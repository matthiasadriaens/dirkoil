net <- rESN::newESN(as.matrix(output),
as.matrix(input),
n.neurons = 100,
density = 0.9,
back.density = 0.02,
leak.rate = 0.5,
lambda = 10)
net<- rESN::trainR(net)
to.predict <- input
Yp <- rESN::predictR(net,u=as.matrix(to.predict))
plot(Yp,type = 'l')
rm(net)
net <- rESN::newESN(as.matrix(output),
as.matrix(input),
n.neurons = 100,
density = 1,
back.density = 0.02,
leak.rate = 0.5,
lambda = 10)
net<- rESN::trainR(net)
to.predict <- input
Yp <- rESN::predictR(net,u=as.matrix(to.predict))
plot(Yp,type = 'l')
rm(net)
net <- rESN::newESN(as.matrix(output),
as.matrix(input),
n.neurons = 1000,
density = 1,
back.density = 0.02,
leak.rate = 0.5,
lambda = 10)
net<- rESN::trainR(net)
to.predict <- input
Yp <- rESN::predictR(net,u=as.matrix(to.predict))
plot(Yp,type = 'l')
rm(net)
net <- rESN::newESN(as.matrix(output),
as.matrix(input),
n.neurons = 1000,
density = 0.2,
back.density = 0.02,
leak.rate = 0.5,
lambda = 10)
net<- rESN::trainR(net)
to.predict <- input
Yp <- rESN::predictR(net,u=as.matrix(to.predict))
plot(Yp,type = 'l')
rm(net)
net <- rESN::newESN(as.matrix(output),
as.matrix(input),
n.neurons = 1000,
density = 0.2,
back.density = 0.02,
leak.rate = 0.9,
lambda = 10)
net<- rESN::trainR(net)
to.predict <- input
Yp <- rESN::predictR(net,u=as.matrix(to.predict))
plot(Yp,type = 'l')
rm(net)
net <- rESN::newESN(as.matrix(output),
as.matrix(input),
n.neurons = 1000,
density = 0.2,
back.density = 0.02,
leak.rate = 0.2,
lambda = 10)
net<- rESN::trainR(net)
to.predict <- input
Yp <- rESN::predictR(net,u=as.matrix(to.predict))
plot(Yp,type = 'l')
rm(net)
net <- rESN::newESN(as.matrix(output),
as.matrix(input),
n.neurons = 1000,
density = 0.2,
back.density = 0.02,
leak.rate = 0.05,
lambda = 10)
net<- rESN::trainR(net)
to.predict <- input
Yp <- rESN::predictR(net,u=as.matrix(to.predict))
plot(Yp,type = 'l')
rm(net)
net <- rESN::newESN(as.matrix(output),
as.matrix(input),
n.neurons = 1000,
density = 0.2,
back.density = 0.02,
leak.rate = 0.005,
lambda = 10)
net<- rESN::trainR(net)
to.predict <- input
Yp <- rESN::predictR(net,u=as.matrix(to.predict))
plot(Yp,type = 'l')
rm(net)
net <- rESN::newESN(as.matrix(output),
as.matrix(input),
n.neurons = 1000,
density = 0.2,
back.density = 0.02,
leak.rate = 0.015,
lambda = 10)
net<- rESN::trainR(net)
to.predict <- input
Yp <- rESN::predictR(net,u=as.matrix(to.predict))
plot(Yp,type = 'l')
rm(net)
net <- rESN::newESN(as.matrix(output),
as.matrix(input),
n.neurons = 1000,
density = 0.2,
back.density = 0.02,
leak.rate = 0.01,
lambda = 10)
net<- rESN::trainR(net)
to.predict <- input
Yp <- rESN::predictR(net,u=as.matrix(to.predict))
plot(Yp,type = 'l')
rm(net)
net <- rESN::newESN(as.matrix(output),
as.matrix(input),
n.neurons = 1000,
density = 0.2,
back.density = 0.02,
leak.rate = 0.1,
lambda = 10)
net<- rESN::trainR(net)
to.predict <- input
Yp <- rESN::predictR(net,u=as.matrix(to.predict))
plot(Yp,type = 'l')
rm(net)
net <- rESN::newESN(as.matrix(output),
as.matrix(input),
n.neurons = 1000,
density = 0.2,
back.density = 0.02,
leak.rate = 0.1,
lambda = 100)
net<- rESN::trainR(net)
to.predict <- input
Yp <- rESN::predictR(net,u=as.matrix(to.predict))
plot(Yp,type = 'l')
rm(list = ls())
?seq
# Generate a sin wave with frequency controlled by a step function
x          <- seq(0, 10*pi, length.out = 500)
plot(x)
trainData  <- matrix(c(rep(.5,500), rep(1,500), rep(.5,500)), ncol = 1)
plot(trainData)
targetData <- matrix(c(sin(x), sin(2*x), sin(x)), ncol = 1)
testData   <- matrix(c(rep(.5,500), rep(.5,500), rep(1,500)), ncol = 1)
plot(targetData)
plot(testData)
# Plot training data
par(mfrow = c(2,1), mar = c(4.5,4.5,2,2))
plot(1:length(trainData), trainData,
ylim = c(-2, 2),
xlab = 'Time', ylab = 'Activation',
type = 'l', lwd = 2)
lines(1:length(targetData), targetData,
lwd = 2, col = 'green')
esnet <- function(inData, outData, resSize,
a = .3, lambda = 1, reg = .001,
discard = 0, resCon = .1, feedback = T){
# Function creates an ESN object with parameters
#   inData:   Input time series
#   outData:  Target time series
#   resSize:  Number of nodes in the reservoir
#   a:        Leak rate
#   lambda:   Desired spectral radius of the reservoir
#   reg:      Regularization parameter for ridge regression
#   discard:  Number of initial samples to discard. Used
#             to wash out the initial reservoir state
#   resCon:   Expected proportion of nonzero elements in W
#   feedback: If true, output feeds back into reservoir
# Output weights are estimated by ridge regression using the
# Moore-Penrose pseudoinverse. This is accurate, but slow for
# very large networks. Similarly, the spectral radius of the
# reservoir is computed exactly, which is innefficient for very
# large reservoir sizes.
#
# Function outputs an ESN object containing the trained weights
# and other network parameter.
# Network dimensions
inSize  <- dim(inData)[2]
outSize <- dim(outData)[2]
n       <- dim(inData)[1]
# Initialize (sparse) weight matrices
Win <- matrix(runif(resSize*(inSize+1), -.5, .5), resSize)
W   <- matrix(runif(resSize*resSize,    -.5, .5), resSize) *
matrix(rbinom(resSize*resSize, 1, resCon), resSize)
Wfb <- matrix(runif(resSize*outSize, -.5, .5), resSize) *
ifelse(feedback, 1, 0)
# Compute and scale spectral radius
specRad <- abs(eigen(W, only.values = TRUE)$values[1])
W       <- (W / specRad) * lambda
# Pass input data through network
X <- matrix(0, 1 + inSize + resSize, n - discard)
# set the corresponding target matrix directly
Y <- matrix(outData[(discard+1):n,],1)
# Pass data through the reservoir
x <- rep(0,resSize)
for (t in 1:n){
uin  <- inData[t,]
uout <- ifelse(t == 1, 0, outData[t-1,])
x    <- (1-a)*x + a*tanh( W %*% x + Win %*% rbind(1,uin) + Wfb * uout)
if (t > discard) X[,t-discard] <- rbind(1,uin,x)
}
# Train output weights by ridge regression
# There are packages that will do this more efficiently,
# but for a small data set, a naive implementation is fine
Wout <- Y %*% t(X) %*% solve( X %*% t(X) + reg*diag(1 + inSize + resSize) )
# Assemble Object
data <- list(
inSize  = inSize,
outSize = outSize,
resSize = resSize,
Win     = Win,
W       = W,
Wout    = Wout,
Wfb     = Wfb,
a       = a,
lambda  = lambda,
reg     = reg,
resCon  = resCon
)
class(data) <- append(class(data), 'EchoState')
return(data)
}
predict.esnet = function(object, input){
# Passes new data through a trained ESN object. Function accepts
# two arguments:
#   object: ESN object
#   input:  Matrix of training input (each row an observation)
# Network parameters
n    <- dim(input)[1]
a    <- object$a
W    <- object$W
Win  <- object$Win
Wout <- object$Wout
Wfb  <- object$Wfb
Y <- matrix(0, object$outSize, n)
x <- rep(0, object$resSize)
uout <- Y[,1]
for (t in 1:n){
uin   <- input[t,]
x     <- (1-a)*x + a*tanh( W %*% x + Win %*% rbind(1,uin) + Wfb %*% uout)
y     <- Wout %*% rbind(1,uin,x)
Y[,t] <- y
uout  <- y
}
return(Y)
}
# Train network
net = esnet(inData = trainData, outData = targetData,
lambda = lambda, a = a, resSize = resSize,
reg = reg, discard = discard, resCon = resCon,
feedback = T)
pred = predict.esnet(net, testData)
# Set parameters
set.seed(42)
a       <- 0.2
lambda  <- .55
resSize <- 1000
reg     <- .0025
discard <- 100
resCon  <- .1
feedback = T
net = esnet(inData = trainData, outData = targetData,
lambda = lambda, a = a, resSize = resSize,
reg = reg, discard = discard, resCon = resCon,
feedback = T)
pred = predict.esnet(net, testData)
plot(pred)
# Plot network output
plot(1:length(testData), testData,
ylim = c(-2, 2),
xlab = 'Time', ylab = 'Prediction',
type = 'l', lwd = 2)
lines(1:length(pred), pred,
lwd = 2, col = 'red')
plot(testData)
testData   <- matrix(c(rep(.5,500), rep(.5,500), rep(0.2,500)), ncol = 1)
pred = predict.esnet(net, testData)
# Plot network output
plot(1:length(testData), testData,
ylim = c(-2, 2),
xlab = 'Time', ylab = 'Prediction',
type = 'l', lwd = 2)
lines(1:length(pred), pred,
lwd = 2, col = 'red')
testData   <- matrix(c(rep(.5,500), rep(.5,500), rep(1,500)), ncol = 1)
pred = predict.esnet(net, testData)
# Plot network output
plot(1:length(testData), testData,
ylim = c(-2, 2),
xlab = 'Time', ylab = 'Prediction',
type = 'l', lwd = 2)
lines(1:length(pred), pred,
lwd = 2, col = 'red')
testData   <- matrix(c(rep(.5,500), rep(.5,500), rep(0.7,500)), ncol = 1)
pred = predict.esnet(net, testData)
# Plot network output
plot(1:length(testData), testData,
ylim = c(-2, 2),
xlab = 'Time', ylab = 'Prediction',
type = 'l', lwd = 2)
lines(1:length(pred), pred,
lwd = 2, col = 'red')
testData   <- matrix(c(rep(.5,500), rep(.5,500), rep(0.6,500)), ncol = 1)
pred = predict.esnet(net, testData)
# Plot network output
plot(1:length(testData), testData,
ylim = c(-2, 2),
xlab = 'Time', ylab = 'Prediction',
type = 'l', lwd = 2)
lines(1:length(pred), pred,
lwd = 2, col = 'red')
plot(trainData)
rm(list = ls())
# Generate a sin wave with frequency controlled by a step function
x          <- seq(0, 10*pi, length.out = 500)
trainData  <- matrix(c(rep(.5,500), rep(1,500), rep(.5,500)), ncol = 1)
targetData <- matrix(c(sin(x), sin(2*x), sin(x)), ncol = 1)
testData   <- matrix(c(rep(.5,500), rep(.5,500), rep(1,500)), ncol = 1)
library(EchoStateNet)
matth <- createESN(leaking.rate = 0.2,
lambda = 0.5,
spectral.radius = 0.5,
n.neurons = 1000,
U = as.matrix(trainData),
Y = as.matrix(targetData))
matth <- EchoStateNet::train(matth)
Ym <- EchoStateNet::predict(matth, U =as.matrix(testData))
plot(Ym,type = 'l')
Ym
rm(list = ls())
# Generate a sin wave with frequency controlled by a step function
x          <- seq(0, 10*pi, length.out = 500)
trainData  <- matrix(c(rep(.5,500), rep(1,500), rep(.5,500)), ncol = 1)
targetData <- matrix(c(sin(x), sin(2*x), sin(x)), ncol = 1)
testData   <- matrix(c(rep(.5,500), rep(.5,500), rep(1,500)), ncol = 1)
###############################################################
library(EchoStateNet)
matth <- createESN(leaking.rate = 0.3,
lambda = 0.5,
spectral.radius = 0.5,
n.neurons = 1000,
U = as.matrix(trainData),
Y = as.matrix(targetData))
matth <- EchoStateNet::train(matth)
Ym <- EchoStateNet::predict(matth, U =as.matrix(testData))
plot(Ym,type = 'l')
rm(list = ls())
# Generate a sin wave with frequency controlled by a step function
x          <- seq(0, 10*pi, length.out = 500)
trainData  <- matrix(c(rep(.5,500), rep(1,500), rep(.5,500)), ncol = 1)
targetData <- matrix(c(sin(x), sin(2*x), sin(x)), ncol = 1)
testData   <- matrix(c(rep(.5,500), rep(.5,500), rep(1,500)), ncol = 1)
###############################################################
library(EchoStateNet)
matth <- createESN(leaking.rate = 0.3,
lambda = 1,
spectral.radius = 0.5,
n.neurons = 1000,
U = as.matrix(trainData),
Y = as.matrix(targetData))
matth <- EchoStateNet::train(matth)
Ym <- EchoStateNet::predict(matth, U =as.matrix(testData))
plot(Ym,type = 'l')
#Sinewave generator
install.packages('ggplot2')
library(ggplot2)
install.packages('gridExtra')
devtools::install_github("matthiasadriaens/EchoStateNet")
require(gridExtra)
library(EchoStateNet)
rm(list = ls())
set.seed(100)
# Generate a sin wave with frequency controlled by a step function
x          <- seq(0, 10*pi, length.out = 500)
trainData  <- matrix(c(rep(0.5,500), rep(0.5,500), rep(1,500)), ncol = 1)
targetData <- matrix(c(sin(x), sin(x), sin(2*x)), ncol = 1)
testData   <- matrix(c(rep(1,500), rep(1,300), rep(0.5,300)), ncol = 1)
###############################################################
matth <- createESN(leaking.rate = 0.55,
lambda = 1,
n.neurons = 1000,
wash.out = 0,
feedback = FALSE,
regCoef = 0.025,
resCon = 1,
U = as.matrix(trainData),
Y = as.matrix(targetData))
matth <- EchoStateNet::train(matth)
Ym <- EchoStateNet::predict(matth, U =as.matrix(testData),generative = FALSE,genNum = 0)
plot(Ym,type = 'l')
---
title: "EchoStateNet package demostration"
output:
pdf_document: default
html_notebook: default
---
###Mackey-Glass equation example
This is a notebook to demostrate the implementation of the echo state network implementation of the R package 'EchoStateNet'.
The goal of the demostration is to predict a part of the Mackey-Glass equation after training the network with appropriate data. The data that is used in this example can be found in the /data folder of the package. It is possible to play with the parameters and get a grasp on this implementation.
Let us start with setting the training, testing and initLen and loading the appropriate packages.
install.packages('ggplot2')
devtools::install_github("matthiasadriaens/EchoStateNet")
library(EchoStateNet)
library(ggplot2)
rm(list = ls())
set.seed(42)
# load the data
trainLen = 2000
testLen = 2000
initLen = 100
install.packages("ggplot2")
data = as.matrix(read.table('MackeyGlass_t17.txt'))
#Inputmatrix
u = as.matrix(data[1:trainLen])
#Outputmatrix
Yt = matrix(data[2:(trainLen+1)])
net <-   createESN(leaking.rate = 0.35,
lambda = 1.25,
n.neurons = 1000,
wash.out = 100,
feedback = FALSE,
regCoef = 1e-8,
resCon = 1,
U = u,
Y = Yt)
library(EchoStateNet)
net <-   createESN(leaking.rate = 0.35,
lambda = 1.25,
n.neurons = 1000,
wash.out = 100,
feedback = FALSE,
regCoef = 1e-8,
resCon = 1,
U = u,
Y = Yt)
net <- EchoStateNet::train(net)
to.predict <- as.matrix(data[(trainLen+3):2501])
Yp <- EchoStateNet::predict(net,
U =to.predict,
generative = TRUE,
genNum = 2000)
Y <- as.matrix(data[(trainLen+3):4003])
df <- as.data.frame(cbind(Yp,Y,1:2001))
names(df) <- c("Yp","Yt","index")
ggplot(df,aes(x = index,y = Yp,colour = "black"),size = 1) +
geom_line() +
geom_line(aes(x = index,y = Yt,colour = 'Targeted signal'),size=1) +
labs(x = "Index",
y = "Targeted and predicted signal",
title = "ESN Mackey-Glass prediction") +
scale_color_discrete(name = "Signals", labels = c("Predicted signal", "Targeted signal"))
library(ggplot2)
Y <- as.matrix(data[(trainLen+3):4003])
df <- as.data.frame(cbind(Yp,Y,1:2001))
names(df) <- c("Yp","Yt","index")
ggplot(df,aes(x = index,y = Yp,colour = "black"),size = 1) +
geom_line() +
geom_line(aes(x = index,y = Yt,colour = 'Targeted signal'),size=1) +
labs(x = "Index",
y = "Targeted and predicted signal",
title = "ESN Mackey-Glass prediction") +
scale_color_discrete(name = "Signals", labels = c("Predicted signal", "Targeted signal"))
install.packages("tinytex")
library(tinytex)
shiny::runApp('C:/Users/matth/OneDrive/Desktop/lngapp')
runApp('C:/Users/matth/OneDrive/Desktop/lngapp')
runApp('C:/Users/matth/OneDrive/Desktop/lngapp')
runApp('C:/Users/matth/OneDrive/Desktop/lngapp')
runApp('C:/Users/matth/OneDrive/Desktop/lngapp')
runApp('C:/Users/matth/OneDrive/Desktop/lngapp')
runApp('C:/Users/matth/OneDrive/Desktop/lngapp')
runApp('C:/Users/matth/OneDrive/Desktop/lngapp')
runApp('C:/Users/matth/OneDrive/Desktop/lngapp')
runApp('C:/Users/matth/OneDrive/Desktop/lngapp')
runApp('C:/Users/matth/OneDrive/Desktop/lngapp')
runApp('C:/Users/matth/OneDrive/Desktop/lngapp')
runApp('C:/Users/matth/OneDrive/Desktop/lngapp')
runApp('C:/Users/matth/OneDrive/Desktop/lngapp')
shiny::runApp('C:/Users/matth/OneDrive/Desktop/lngapp')
deployApp()
library(rsconnect)
deployApp()
getwd()
setwd("C:/Users/matth/OneDrive/Documents/Desktop")
setwd("C:/Users/matth/OneDrive/Desktoop")
setwd("C:/Users/matth/OneDrive/Desktop")
deployApp()
getwd()
setwd("C:/Users/matth/OneDrive/Desktop/lngapp")
deployApp()
runApp()
runApp()
runApp()
runApp()
runApp()
install.packages("geosphere")
runApp()
library(geosphere)
runApp()
getwd()
deployApp()
deployApp()
runApp()
runApp()
